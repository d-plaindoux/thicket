/*
 * Thicket
 * https://github.com/d-plaindoux/thicket
 *
 * Copyright (c) 2015-2016 Didier Plaindoux
 * Licensed under the LGPL2 license.
 */
 
 
module Parser.JSon

from Data.Number import number
from Data.Character import char
from Data.String import string
from Data.List import list, emptyList, List
from Data.Pair import Pair
from Data.Option import some
from Data.Try import try
from Data.JSon import *
from Data.Sequence import sequence

from Parser.LL import *
from Parser.Genlex import *
from Parser.Token import *
from Parser.Tokenizer import *

def jsonArray : Parser[list[JSon],Token] = {
  (jsonExpr ~ (tkKeyword match ',' ~> jsonArray ?)    
        map $ r -> r._2 fold emptyList (l -> l) +: r._1)
| (return emptyList)
}

def jsonObject : Parser[list[(string,JSon)],Token] = {
  (tkString ~ (tkKeyword match ":" ~> jsonExpr) ~ (tkKeyword match "," ~> jsonObject ?)
        map $ r -> r._2 fold emptyList (l -> l) +: r._1)
| (return emptyList)
}

def jsonExpr : Parser[JSon,Token] = {
  (tkString map $ JSonString)        
| (tkNumber map $ JSonNumber)        
| (tkKeyword match "[" ~> jsonArray  <~ (tkKeyword match "]") map $ JSonArray)
| (tkKeyword match "{" ~> jsonObject <~ (tkKeyword match "}") map $ JSonObject)
| (tkIdent match "null" map $ _ -> JSonNull)       
}

def tokenize : string -> try[sequence[Token]] = {
    let keywords = List[":";",";"{";"}";"[";"]"] in
        tokenize from Parser.Tokenizer $ genlex $ some keywords
}

def decode : string -> try[JSon] = s -> { 
    for tokens <- { tokenize s }
        json   <- { jsonExpr parse tokens 0 toTry }
    yield json
}

